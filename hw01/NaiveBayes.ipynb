{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "NaiveBayes.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDf_cqujthgZ"
      },
      "source": [
        "# Реализуем методы для наивного байеса"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0tezH48thgb"
      },
      "source": [
        "Сгенерируем выборку, в которой каждый признак имеет некоторое своё распределение, параметры которого отличаются для каждого класса. Затем реализуем несколько методов для класса, который уже частично написан ниже:\n",
        "- метод predict\n",
        "- метод \\_find\\_expon\\_params и \\_get\\_expon\\_density для экспоненциального распределения\n",
        "- метод \\_find\\_norm\\_params и \\_get\\_norm\\_probability для биномиального распределения\n",
        "\n",
        "Для имплементации \\_find\\_something\\_params изучите документацию функций для работы с этими распределениями в scipy.stats и используйте предоставленные там методы."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJj4WdGDthgc"
      },
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "import scipy.stats"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3SOQhOBthgd"
      },
      "source": [
        "Сформируем параметры генерации для трех датасетов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wzYmquVthge",
        "outputId": "74738960-1227-4f32-cb58-f6795b543e6e"
      },
      "source": [
        "func_params_set0 = [(scipy.stats.bernoulli, [dict(p=0.1), dict(p=0.5)]),\n",
        "                   ]\n",
        "\n",
        "func_params_set1 = [(scipy.stats.bernoulli, [dict(p=0.1), dict(p=0.5)]),\n",
        "                    (scipy.stats.expon, [dict(scale=1), dict(scale=0.3)]),\n",
        "                   ]\n",
        "\n",
        "func_params_set2 = [(scipy.stats.bernoulli, [dict(p=0.1), dict(p=0.5)]),\n",
        "                    (scipy.stats.expon, [dict(scale=1), dict(scale=0.3)]),\n",
        "                    (scipy.stats.norm, [dict(loc=0, scale=1), dict(loc=1, scale=2)]),\n",
        "                   ]\n",
        "\n",
        "def generate_dataset_for_nb(func_params_set=[], size = 2500, random_seed=0):\n",
        "    '''\n",
        "    Генерирует выборку с заданными параметрами распределений P(x|y).\n",
        "    Число классов задается длиной списка с параметрами.\n",
        "    Возвращает X, y, список с названиями распределений\n",
        "    '''\n",
        "    np.random.seed(random_seed)\n",
        "\n",
        "    X = []\n",
        "    names = []\n",
        "    for func, params in func_params_set:\n",
        "        names.append(func.name)\n",
        "        f = []\n",
        "        for i, param in enumerate(params):\n",
        "            f.append(func.rvs(size=size, **param))\n",
        "        f = np.concatenate(f).reshape(-1,1)\n",
        "        X.append(f)\n",
        "\n",
        "    X = np.concatenate(X, 1)\n",
        "    y = np.array([0] * size + [1] * size)\n",
        "\n",
        "    shuffle_inds = np.random.choice(range(len(X)), size=len(X), replace=False)\n",
        "    X = X[shuffle_inds]\n",
        "    y = y[shuffle_inds]\n",
        "\n",
        "    return X, y, names \n",
        "\n",
        "X, y, distrubution_names = generate_dataset_for_nb(func_params_set0)\n",
        "X.shape, y.shape, distrubution_names"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5000, 1), (5000,), ['bernoulli'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YufNMGqFthgg"
      },
      "source": [
        "from collections import defaultdict\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "class NaiveBayes(BaseEstimator, ClassifierMixin):\n",
        "    '''\n",
        "    Реализация наивного байеса, которая помимо X, y\n",
        "    принимает на вход во время обучения \n",
        "    виды распределений значений признаков\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def _find_bernoulli_params(self, x):\n",
        "        '''\n",
        "        метод возвращает найденный параметр `p`\n",
        "        распределения scipy.stats.bernoulli\n",
        "        '''\n",
        "        return dict(p=np.mean(x))\n",
        "    \n",
        "    def _get_bernoulli_probability(self, x, params):\n",
        "        '''\n",
        "        метод возвращает вероятность x для данных\n",
        "        параметров распределния\n",
        "        '''\n",
        "        return scipy.stats.bernoulli.pmf(x, **params)\n",
        "\n",
        "    def _find_expon_params(self, x):\n",
        "        # нужно определить параметры распределения\n",
        "        # и вернуть их\n",
        "        return dict(h=np.mean(x) ** -1)\n",
        "    \n",
        "    def _get_expon_density(self, x, params):\n",
        "        # нужно вернуть плотность распределения в x\n",
        "        return scipy.stats.expon.pdf(x, **params)\n",
        "\n",
        "    def _find_norm_params(self, x):\n",
        "        # нужно определить параметры распределения\n",
        "        # и вернуть их\n",
        "        return dict(p = np.mean(x) / x.shape[0], n = x.shape[0])\n",
        "    \n",
        "    def _get_norm_density(self, x, params):\n",
        "        return scipy.stats.binom.pmf(x, **params)\n",
        "\n",
        "    def _get_params(self, x, distribution):\n",
        "        '''\n",
        "        x - значения из распределения,\n",
        "        distribution - название распределения в scipy.stats\n",
        "        '''\n",
        "        if distribution == 'bernoulli':\n",
        "            return self._find_bernoulli_params(x)\n",
        "        elif distribution == 'expon':\n",
        "            return self._find_expon_params(x)\n",
        "        elif distribution == 'norm':\n",
        "            return self._find_norm_params(x)\n",
        "        else:\n",
        "            raise NotImplementedError('Unknown distribution')\n",
        "            \n",
        "    def _get_probability_or_density(self, x, distribution, params):\n",
        "        '''\n",
        "        x - значения,\n",
        "        distribytion - название распределения в scipy.stats,\n",
        "        params - параметры распределения\n",
        "        '''\n",
        "        if distribution == 'bernoulli':\n",
        "            return self._get_bernoulli_probability(x, params)\n",
        "        elif distribution == 'expon':\n",
        "            return self._get_expon_density(x, params)\n",
        "        elif distribution == 'norm':\n",
        "            return self._get_norm_density(x, params)\n",
        "        else:\n",
        "            raise NotImplementedError('Unknown distribution')\n",
        "\n",
        "    def fit(self, X, y, distrubution_names):\n",
        "        '''\n",
        "        X - обучающая выборка,\n",
        "        y - целевая переменная,\n",
        "        feature_distributions - список названий распределений, \n",
        "        по которым предположительно распределны значения P(x|y)\n",
        "        ''' \n",
        "        assert X.shape[1] == len(distrubution_names)\n",
        "        assert set(y) == {0, 1}\n",
        "        self.n_classes = len(np.unique(y))\n",
        "        print('dist names ')\n",
        "        print(distrubution_names)\n",
        "        self.distrubution_names = distrubution_names\n",
        "        \n",
        "        self.y_prior = [(y == j).mean() for j in range(self.n_classes)]\n",
        "        print('y prior ')\n",
        "        print(self.y_prior)\n",
        "\n",
        "        self.distributions_params = defaultdict(dict)\n",
        "        for i in range(X.shape[1]):\n",
        "            distribution = self.distrubution_names[i]\n",
        "            for j in range(self.n_classes):\n",
        "                values = X[y == j, i]\n",
        "                self.distributions_params[j][i] = \\\n",
        "                    self._get_params(values, distribution)\n",
        "        print(self.distributions_params[0])\n",
        "        print(self.distributions_params[1])\n",
        "        return self.distributions_params\n",
        "    \n",
        "    def predict(self, X):\n",
        "        '''\n",
        "        X - тестовая выборка\n",
        "        '''\n",
        "        assert X.shape[1] == len(self.distrubution_names)\n",
        "        \n",
        "        preds = np.zeros(X.shape)\n",
        "        # для каждого распределения делаем предсказание\n",
        "        for i in range(X.shape[1]):\n",
        "            distribution = self.distrubution_names[i]\n",
        "            preds = np.argmax(\n",
        "              [(np.log(self.y_prior[j]) +\n",
        "                np.log(self._get_probability_or_density(X[i:], distribution, self.distributions_params[j][i])))\n",
        "                for j in range(len(self.y_prior))\n",
        "              ], axis = 0\n",
        "            )\n",
        "            \n",
        "        # нужно реализовать подсчет аргмаксной формулы, по которой \n",
        "        # наивный байес принимает решение о принадлежности объекта классу\n",
        "        # и применить её для каждого объекта в X\n",
        "        #\n",
        "        # примечание: обычно подсчет этой формулы реализуют через \n",
        "        # её логарифмирование, то есть, через сумму логарифмов вероятностей, \n",
        "        # поскольку перемножение достаточно малых вероятностей будет вести\n",
        "        # к вычислительным неточностям\n",
        "        \n",
        "        return preds"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VErqg9jithgk"
      },
      "source": [
        "Проверим результат на примере первого распределения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9jrFChTthgm",
        "outputId": "7fd4d324-570b-452a-bbb9-60666ab9c34c"
      },
      "source": [
        "nb = NaiveBayes()\n",
        "nb.fit(X, y, ['bernoulli'])"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dist names \n",
            "['bernoulli']\n",
            "y prior \n",
            "[0.5, 0.5]\n",
            "{0: {'p': 0.1128}}\n",
            "{0: {'p': 0.482}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(dict, {0: {0: {'p': 0.1128}}, 1: {0: {'p': 0.482}}})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRFlSYdf6JLd",
        "outputId": "103daf4b-a36e-4323-accf-1210bea0ccd2"
      },
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 1)\n",
            "(5000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm_PLakuthgn",
        "outputId": "a2c4af27-2705-481b-b164-95ce584a1ec3"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "prediction = nb.predict(X)\n",
        "score = f1_score(y, prediction)\n",
        "print('{:.2f}'.format(score))"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZG8d-Tgthgn"
      },
      "source": [
        "# Ответы для формы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mrdZBGDthgo"
      },
      "source": [
        "Ответом для формы должны служить числа, которые будут выведены ниже. Все ответы проверены: в этих примерах получается одинаковый результат и через сумму логарифмов, и через произведение вероятностей."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "16BTmprzthgo",
        "outputId": "941148c8-9af8-47c3-e363-0baa2a99db7f"
      },
      "source": [
        "scipy.stats.bernoulli.name\n",
        "\n",
        "for fps in (func_params_set0 * 2,\n",
        "            func_params_set1, \n",
        "            func_params_set2):\n",
        "    \n",
        "\n",
        "    X, y, distrubution_names = generate_dataset_for_nb(fps)\n",
        "    \n",
        "    nb = NaiveBayes()\n",
        "    nb.fit(X, y, distrubution_names)\n",
        "    prediction = nb.predict(X)\n",
        "    score = f1_score(y, prediction)\n",
        "    print('{:.2f}'.format(score))"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dist names \n",
            "['bernoulli', 'bernoulli']\n",
            "y prior \n",
            "[0.5, 0.5]\n",
            "{0: {'p': 0.1128}, 1: {'p': 0.0956}}\n",
            "{0: {'p': 0.482}, 1: {'p': 0.4948}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-176-ec0218742e21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistrubution_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{:.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1097\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                        zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1224\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1227\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1484\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1299\u001b[0m                          str(average_options))\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5000, 4999]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTXdoZUethgp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}